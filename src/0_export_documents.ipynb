{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape GeschÃ¤fte\n",
    "Ah I really hate this shitty API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import calendar\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import glob, os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import json\n",
    "from dateutil import parser\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load all GeschÃ¤fte\n",
    "Store them as they are (XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years: 2001 - 2023\n"
     ]
    }
   ],
   "source": [
    "url = 'https://parlzhcdws.cmicloud.ch/parlzh5/cdws/Index/GESCHAEFT/searchdetails?q=%s&l=de-CH'\n",
    "\n",
    "year_from = 2001\n",
    "year_to = 2023\n",
    "print(\"Years: %s - %s\" % (year_from, year_to))\n",
    "\n",
    "for year in range(year_from, year_to):\n",
    "    for i in range(0, 3):\n",
    "        #print(\"%s %s\" % (year, i))\n",
    "\n",
    "        # First day\n",
    "        d_start = '%s-%02d-01 00:00:00' % (year, i * 4 + 1)\n",
    "\n",
    "        # Last day\n",
    "        l = calendar.monthrange(year, (i + 1) * 4)[-1]\n",
    "        d_end = '%s-%02d-%s 23:59:00' % (year, (i + 1) * 4, l)\n",
    "\n",
    "        q = 'beginn_start >= \"%s\" and beginn_start <= \"%s\" sortBy beginn_start/sort.descending krnr/sort.descending' % (d_start, d_end)\n",
    "\n",
    "        r = requests.get(url % urllib.parse.quote(q))\n",
    "        with open(Path('../export/GESCHAEFT/%s_%s.xml' % (year, i)), 'wb') as f:\n",
    "            f.write(r.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Document-DataFrame from XML\n",
    "Logic: \n",
    "*  Search for `AR` (=Abstimmungsresultat). Then you will find ARs since 2020\n",
    "* Search for `Abstimmungsresultat`. Then you will find older results\n",
    "* Search for `Schlussabstimmung`\n",
    "\n",
    "... yes... there is no other way... this API... let's say it nicely... no, better be quiet... ah, I hate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse all XML and create Dataframe\n",
    "ns = {\n",
    "    'g': 'http://www.cmiag.ch/cdws/Geschaeft'\n",
    "    }\n",
    "\n",
    "records = []\n",
    "\n",
    "# Open all xml-files\n",
    "for f in glob.glob(str(Path('../export/GESCHAEFT/*.xml'))):\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Map parents. Need it, to find parents\n",
    "    parent_map = {c:p for p in tree.iter() for c in p}\n",
    "\n",
    "    for g in root.findall('.//g:Ablaufschritt', ns):\n",
    "\n",
    "        for d in g.findall('.//g:Dokument', ns):\n",
    "\n",
    "            # If no version, skip it. Yes, there is unreferenced data in the database...\n",
    "            versions = d.findall('.//g:Version', ns)\n",
    "            if len(versions) == 0:\n",
    "                continue\n",
    "\n",
    "            geschaeft = parent_map[parent_map[g]]\n",
    "\n",
    "            try:\n",
    "                records.append({\n",
    "                    'KRNr': geschaeft.find('g:KRNr', ns).text,\n",
    "                    'VorlageNr': geschaeft.find('g:VorlageNr', ns).text,\n",
    "                    'Titel': geschaeft.find('g:Titel', ns).text,\n",
    "                    'Geschaeftsart': geschaeft.find('g:Geschaeftsart', ns).text,\n",
    "                    'AblaufschrittTyp': g.find('g:AblaufschrittTyp', ns).text,\n",
    "                    'DokumentTitel': d.find('g:Titel', ns).text,\n",
    "                    'eDocumentFileName': d.find('g:eDocument', ns).attrib['FileName'],\n",
    "                    'eDocumentID': d.find('g:eDocument', ns).attrib['ID'],\n",
    "                    'Version': d.findall('.//g:Version', ns)[-1].attrib['Nr'],\n",
    "                    'Sitzungsdatum': g.find('.//g:Sitzungsdatum/g:Start', ns).text,\n",
    "                })\n",
    "\n",
    "            except:\n",
    "                print(d.findall('.//g:Version', ns))\n",
    "                print(g.attrib['OBJ_GUID'])\n",
    "                print(d.attrib['OBJ_GUID'])\n",
    "                raise\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "df = df.sort_values('Sitzungsdatum')\n",
    "\n",
    "# Add URL\n",
    "df['url'] = df.apply(lambda row: 'https://parlzhcdws.cmicloud.ch/parlzh5/cdws/Files/{id}/{version}/pdf'.format(id=row['eDocumentID'], version=row['Version']), axis=1)\n",
    "\n",
    "# Export only \"Abstimmungen\"\n",
    "df_ar = df[\n",
    "    (df.eDocumentFileName.str.startswith('AR')) |\n",
    "    (df.eDocumentFileName.str.contains('Abstimmungsresultat', case=False)) |\n",
    "    (df.eDocumentFileName.str.contains('Schlussabstimmung', case=False))\n",
    "]\n",
    "\n",
    "# Before Lockdown\n",
    "df_ar = df_ar[df_ar['Sitzungsdatum'] < '2020-03-16']\n",
    "\n",
    "df_ar.to_csv(Path('../export/abstimmungen.csv'), index=False)\n",
    "\n",
    "len(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Abstimmungen (PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1118"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load file again\n",
    "df_ar = pd.read_csv(Path('../export/abstimmungen.csv'))\n",
    "df_ar['Sitzungsdatum'] = pd.to_datetime(df_ar['Sitzungsdatum'])\n",
    "\n",
    "len(df_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Documents\n",
    "for i, row in df_ar.iterrows():\n",
    "\n",
    "    fn = Path('../export/eDocuments/%s.pdf' % row['eDocumentID'])\n",
    "\n",
    "    # Skip if already downloaded\n",
    "    if fn.exists():\n",
    "        continue\n",
    "\n",
    "    r = requests.get(row['url'])\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print('File not found', row['url'])\n",
    "\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a876f1708db670be7f139fc4229d20470349cf8d4ab3a0d60446a37364b5cf5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
